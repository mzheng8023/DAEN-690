{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#near duplicate detection and elimination\n",
    "#next steps - obtain more data\n",
    "#near entity recognition - spacy\n",
    "#relabeling\n",
    "\n",
    "# import libraries\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/training_test_data/'\n",
    "data = pd.read_csv(data_path + 'after_stock_data_cleaned.csv')\n",
    "colnames = ['headline','source','label']   \n",
    "data.columns = colnames\n",
    "\n",
    "data2 = pd.read_csv(data_path + 'labeled_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple, Amazon, YouTube: Safer, faster &amp;amp; le...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5G Stocks: Will Amazon Dip Its Toes In?</td>\n",
       "      <td>InvestorPlace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fear of Amazon Creates a Bargain in FedEx Stock</td>\n",
       "      <td>InvestorPlace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Buyout Buzz Draws Options Bulls to Grub...</td>\n",
       "      <td>Schaeffer's Investment Research</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US Stock Market Overview – Stocks Surge With O...</td>\n",
       "      <td>FX Empire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Apple, Amazon, YouTube: Safer, faster &amp; le...   \n",
       "1            5G Stocks: Will Amazon Dip Its Toes In?   \n",
       "2    Fear of Amazon Creates a Bargain in FedEx Stock   \n",
       "3  Amazon Buyout Buzz Draws Options Bulls to Grub...   \n",
       "4  US Stock Market Overview – Stocks Surge With O...   \n",
       "\n",
       "                            source  label  \n",
       "0                        USA TODAY      0  \n",
       "1                    InvestorPlace      0  \n",
       "2                    InvestorPlace      0  \n",
       "3  Schaeffer's Investment Research      0  \n",
       "4                        FX Empire      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset specific cleansing and concatenation\n",
    "\n",
    "#data[data['source'].str.find(' via ') > -1]['source'].str[:data['source'].str.find(' via ')]\n",
    "\n",
    "for i, row in data[data['source'].str.find(' via ') > -1].iterrows():\n",
    "  data.at[i,'source'] = data.at[i,'source'][:data.at[i,'source'].find(' via ')].strip()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "headlines = []\n",
    "\n",
    "for i, row in data2.iterrows():\n",
    "    sources.append(data2.at[i, 'headlines'][len(data2.at[i, 'headlines'])-data2.at[i, 'headlines'][::-1].find('-'):].strip())\n",
    "    headlines.append(data2.at[i, 'headlines'][:len(data2.at[i, 'headlines'])-data2.at[i, 'headlines'][::-1].find('-')-1].strip())                                \n",
    "    \n",
    "sources[:10] \n",
    "headlines[:10] \n",
    "\n",
    "clean_data2 = pd.DataFrame({'headline':headlines, 'source':sources, 'label':data2['relevancy']}, columns=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple, Amazon, YouTube: Safer, faster &amp;amp; le...</td>\n",
       "      <td>USA TODAY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5G Stocks: Will Amazon Dip Its Toes In?</td>\n",
       "      <td>InvestorPlace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fear of Amazon Creates a Bargain in FedEx Stock</td>\n",
       "      <td>InvestorPlace</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Buyout Buzz Draws Options Bulls to Grub...</td>\n",
       "      <td>Schaeffer's Investment Research</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US Stock Market Overview – Stocks Surge With O...</td>\n",
       "      <td>FX Empire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Apple, Amazon, YouTube: Safer, faster &amp; le...   \n",
       "1            5G Stocks: Will Amazon Dip Its Toes In?   \n",
       "2    Fear of Amazon Creates a Bargain in FedEx Stock   \n",
       "3  Amazon Buyout Buzz Draws Options Bulls to Grub...   \n",
       "4  US Stock Market Overview – Stocks Surge With O...   \n",
       "\n",
       "                            source  label  \n",
       "0                        USA TODAY      0  \n",
       "1                    InvestorPlace      0  \n",
       "2                    InvestorPlace      0  \n",
       "3  Schaeffer's Investment Research      0  \n",
       "4                        FX Empire      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate our data to their data\n",
    "\n",
    "df_union = pd.concat([data, clean_data2])\n",
    "\n",
    "df_union.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4093\n",
      "4093\n"
     ]
    }
   ],
   "source": [
    "###placeholder cell, shingle and near duplicate elimination\n",
    " \n",
    " \n",
    "def get_shingles(doc, size):\n",
    "    shingles = set()\n",
    "    if len(doc) > size:\n",
    "        for i in range(0, len(doc)-size+1):\n",
    "            shingles.add(doc[i:i+size])\n",
    "    return shingles\n",
    " \n",
    "def jaccard(set1, set2):\n",
    "    x = len(set1.intersection(set2))\n",
    "    y = len(set1.union(set2))\n",
    "    return x / float(y)\n",
    "\n",
    "def remove_near_dups(df, textcol, threshold):\n",
    "    shingles = []\n",
    "\n",
    "    for text in df[textcol]:\n",
    "        shingles.append(get_shingles(text, 4))\n",
    " \n",
    "    df['shingles'] = shingles\n",
    "    \n",
    "    return df\n",
    "    \n",
    "    rows = []\n",
    "    dups = {}\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        if i < len(df):\n",
    "            for j in range(i+1,len(df)):\n",
    "                if jaccard(df.at[i, 'shingles'], df.at[j, 'shingles']) > threshold:\n",
    "                    dups.append(j)\n",
    "                    \n",
    "    print(dups)\n",
    "                    \n",
    "    for i, row in df.iterrows():\n",
    "        if i not in dups:\n",
    "            rows.append(row[:-1])\n",
    "    \n",
    "    return pd.DataFrame(rows, columns = df.columns)\n",
    "            \n",
    "        \n",
    "        #data2.at[i, 'headlines']\n",
    "    \n",
    "new_df = remove_near_dups(df_union, 'headline', .4)\n",
    "print(len(df_union))\n",
    "print(len(new_df))\n",
    "                                      \n",
    "\n",
    "#print(jaccard(shingles1, shingles2), file1, file2)\n",
    "\n",
    "#for i in range(i, len(data_union['headline']):\n",
    "#for j in range(i,len(data_union['headline'])):\n",
    "#print(jaccard(shingles1, shingles2), file1, file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2840\n",
       "0    1253\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_union['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df_union['headline'] = df_union['headline'].str.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count = sum(len(headline) for headline in df_union['headline'])\n",
    "\n",
    "#print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3274,819\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation set\n",
    "df_trn, df_val = train_test_split(df_union[['label','headline']], stratify = df_union['label'], test_size = 0.2, random_state = 12)\n",
    "print(str(len(df_trn))+ ',' + str(len(df_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_headlines = pd.read_csv(r'C:\\Users\\amber\\Documents\\VSE\\DAEN 690\\repo\\DAEN-690\\data\\raw_data\\Nowigence Raw Data.csv')\n",
    "\n",
    "unlabeled_headlines.columns = ['headline']\n",
    "\n",
    "text_df = pd.DataFrame(pd.concat([df_union['headline'], unlabeled_headlines['headline']]))\n",
    "text_df['label'] = 0\n",
    "\n",
    "txt_trn, txt_val = train_test_split(text_df[['label','headline']], stratify = text_df['label'], test_size = 0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language model data\n",
    "data_lm = TextLMDataBunch.from_df(train_df = txt_trn, valid_df = txt_val, path = \"\", num_workers = 2)\n",
    "\n",
    "# Classifier model data\n",
    "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data_lm, arch=AWD_LSTM, drop_mult=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.734873</td>\n",
       "      <td>2.398154</td>\n",
       "      <td>0.572411</td>\n",
       "      <td>12:24:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I probably don't need to import all of these...I'll do more research to figure out just what I'm using below\n",
    "\n",
    "from fastai.torch_core import *\n",
    "from fastai.callback import *\n",
    "from fastai.layers import *\n",
    "from fastai.basic_train import LearnerCallback\n",
    "\n",
    "#based on fastai's built in fbeta and accuracy metrics - the fbeta that is built in only works on one hot encoded multiclass targets\n",
    "\n",
    "def fscore(y_pred:Tensor, y_true:Tensor, thresh:float=0.2, beta:float=2, eps:float=1e-9, sigmoid:bool=True)->Rank0Tensor:\n",
    "    \"Computes the f_beta between `preds` and `targets`\"\n",
    "    beta2 = beta ** 2\n",
    "    n = y_true.shape[0]\n",
    "    if sigmoid: y_pred = y_pred.sigmoid()\n",
    "    y_pred = y_pred.argmax(dim=-1).view(n,-1)\n",
    "    y_true = y_true.view(n,-1)\n",
    "    TP = (y_pred*y_true).float().sum()\n",
    "    prec = TP/(y_pred.float().sum()+eps)\n",
    "    rec = TP/(y_true.float().sum()+eps)\n",
    "    res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)\n",
    "    return res.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('ft_enc')\n",
    "learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.7, metrics = fscore)\n",
    "learn.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>fscore</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>0.555886</td>\n",
       "      <td>0.903449</td>\n",
       "      <td>02:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
